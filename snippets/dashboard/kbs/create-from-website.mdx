## Website data source

Transform your website content into intelligent knowledge bases that power your AI Agents. This method automatically discovers, scrapes, and processes web pages to create comprehensive knowledge repositories.

### What you get

- **Automatic content discovery** from your website structure
- **Text extraction** from web pages and structured data
- **Link following** to discover related content
- **Content organization** and indexing for optimal search
- **Dynamic content support** for JavaScript-heavy sites

### Perfect for

- **Company websites** with product information and documentation
- **Help centers** and support documentation
- **Blog content** and articles
- **Documentation sites** and wikis
- **E-commerce sites** with product catalogs

### Step-by-step creation process

<Steps>

    <Step title="Select Website data source">
      Navigate to the Create Knowledge Base section and click on the `Website URL` card to begin creating a website-based knowledge base.

      <Frame>
        <img src="/images/dashboard/agent/knowledge/website/step-1.png" alt="Create Knowledge Base page showing Website URL card selection" />
      </Frame>

      <Check>
        This opens the knowledge base configuration modal where you can set up your website scraping parameters.
      </Check>
    </Step>

<Step title="Configure basic settings">
  Set up the fundamental information for your knowledge base in the basic
  configuration section.
  <Frame>
    <img
      src="/images/dashboard/agent/knowledge/website/step-2-basic.png"
      alt="Basic configuration showing knowledge base name and URL fields"
    />
  </Frame>
  **Required fields:** 
  - **Knowledge Base Name**: Enter a descriptive name for your knowledge base 
  - **Website Base URL**: Provide the base URL of the website you want to scrape
  <Info>
    The system will use this URL as the starting point for content discovery and
    crawling.
  </Info>
</Step>

<Step title="Configure advanced scraping settings">
  Customize the scraping behavior and parameters for optimal content extraction.
  <Frame>
    <img
      src="/images/dashboard/agent/knowledge/website/step-2-advanced.png"
      alt="Advanced settings showing scraping configuration options"
    />
  </Frame>
**Advanced Configuration Options:**

- **Number of URLs to Scrape**: Specify the maximum number of pages to crawl. The default is 200, with a maximum limit of 10,000.
- **Crawl Depth**: Set the number of levels deep to crawl within the website hierarchy. The default is 20, with a maximum of 100.
- **Custom User Agent**: Provide an optional custom identification string for web requests.
- **Base URL Crawling**: Limit crawling to a single level by using only base URLs, ignoring the depth setting.
- **Browser Rendering**: Enable this option to render content using a browser for sites with dynamic JavaScript.
- **Scraper Engine**: Choose between the legacy Scrapy engine and the modern Crawl4AI engine.
  <Tip>
    **Optimal Settings**: For most websites, default settings work well. Use
    browser rendering for JavaScript-heavy sites and adjust depth based on your
    site structure.
  </Tip>
</Step>

<Step title="Add knowledge base">
  Click the `Add Knowledge Base` button to create your knowledge base with the
  configured settings.
  <Frame>
    <img
      src="/images/dashboard/agent/knowledge/website/step-3-add-knowledge.png"
      alt="Add Knowledge Base button to proceed with creation"
    />
  </Frame>
  <Check>
    Your knowledge base is created and you're redirected to the configuration
    page where you can manage data resources.
  </Check>
</Step>

<Step title="Review knowledge base configuration">
  View your newly created knowledge base configuration page with the added data
  resource.
  <Frame>
    <img
      src="/images/dashboard/agent/knowledge/website/step-4-overview.png"
      alt="Knowledge base configuration page showing added data source"
    />
  </Frame>
  **Configuration Overview:**
  - **Data Resources**: Displays the base URL of the website you have added.
  - **Fetch Links**: Initiates the scraping process.
  - **Indexing Type**: Choose from Sentence level Indexing or Section level Indexing. The default is Sentence level Indexing.
  - **Training Status**: Shows the current processing state of your knowledge base.
  - **Load Method**: Choose how the system retrieves web content. Select between Direct request, which fetches data directly from the server, or Browser environment, which simulates a browser to render and extract content. The default is Direct request if `Use browser` is disabled.
  - **Menu Actions**: Provides options to delete the added data resource.
  <Info>
    This page serves as your central hub for managing all aspects of your
    knowledge base.
  </Info>
</Step>

<Step title="Initiate content fetching">
  Click the `Fetch Links` button to begin the web scraping process.
  <Frame>
    <img
      src="/images/dashboard/agent/knowledge/website/step-5-while-fetch.png"
      alt="Active fetching process showing real-time scraping progress and logs"
    />
  </Frame>
  **Fetching Process:**
  - **Content Discovery**: The system identifies and navigates through web pages.
  - **Text Extraction**: Content is extracted from each identified page.
  - **Data Processing**: Extracted content is cleaned and organized.
  - **Progress Monitoring**: Real-time logs display scraping activity and status updates.
  <Warning>
    **Scraping Time**: The fetching process may take several minutes depending
    on website size and complexity. Monitor the progress logs for detailed
    status updates.
  </Warning>
</Step>

<Step title="Review and Select Pages">
  After fetching completes, review the extracted content and select pages for
  training.
  <Frame>
    <img
      src="/images/dashboard/agent/knowledge/website/step-7-pre-train.png"
      alt="Post-fetch state showing completed scraping with content ready for training"
    />
  </Frame>
  **Review and Selection:**
  - **Extracted Pages**: Access a list of all discovered and scraped web pages, each with clickable links.
  - **Word Count**: Review the number of words extracted from each page.
  - **Page Selection**: Select specific pages to include in the training process.
  - **Pre-filtering**: Filter pages based on content relevance and word count to optimize training preparation.
  <Check>
    All content has been successfully extracted, and you can now select the
    desired pages for the training phase.
  </Check>
</Step>

<Step title="Training and Monitoring">
  Initiate the training process and monitor the real-time progress as your
  content is processed and indexed.
  <Frame>
    <img
      src="/images/dashboard/agent/knowledge/website/step-7-post-train.png"
      alt="Pre-training state showing content ready for knowledge base training"
    />
  </Frame>
  **Training Phase:**
  - **Initiate Training**: Begin by clicking the `Train` button to start the AI processing.
  - **Data Reading**: The system reads and imports the stored data resources for processing.
  - **URL Filtering**: Unnecessary URLs are filtered out to ensure only relevant data is processed.
  - **Text Chunking**: The text is divided into smaller, manageable chunks for efficient processing.
  - **Embedding Generation**: These text chunks are converted into vector embeddings using AI models.
  - **Vector Storage**: The generated embeddings are stored in vector databases like Qdrant and Weaviate for efficient retrieval.
  - **Index Optimization**: The system optimizes the index to enhance search and retrieval performance.
  <Check>
    Once the training is complete, your knowledge base will be fully functional and ready for integration with AI Agents.
  </Check>
</Step>

<Step title="View Extracted Content">
  If you wish to see the content of the training after the post-train phase,
  click on the particular link that is fetched to view the extracted content.
  <Frame>
    <img
      src="/images/dashboard/agent/knowledge/website/step-7-pre-view-content.png"
      alt="Preview of content ready for review"
    />
  </Frame>
  <Frame>
    <img
      src="/images/dashboard/agent/knowledge/website/step-7-extracted-content.png"
      alt="Detailed view of extracted content"
    />
  </Frame>
  **Content Viewing:**
  - **Preview Content**: Click on the links to view detailed content extracted from each page.
  - **Content Analysis**: Evaluate the quality and relevance of the extracted data for further refinement.
</Step>

<Step title="Add additional data sources (optional)">
  Optionally add more data sources to expand your knowledge base content.
  <Frame>
    <img
      src="/images/dashboard/agent/knowledge/website/step-8-new-datasource.png"
      alt="Add new data source option for expanding knowledge base"
    />
  </Frame>
    **Additional Data Sources:**
    - **Add Data Resource**: Click to add more websites or content sources.
    - **Same Configuration**: Use the same modal interface for additional sources.
    - **Multiple Sources**: Combine content from multiple websites or URLs.
    - **Unified Knowledge**: All sources contribute to a single comprehensive knowledge base.
  <Tip>
    **Expanding Content**: Adding multiple data sources creates more
    comprehensive knowledge bases with broader coverage of your domain.
  </Tip>
</Step>

<Step title="Train additional content">
  Process and train any newly added data sources to integrate them into your
  knowledge base.
  <Frame>
    <img
      src="/images/dashboard/agent/knowledge/website/step-9-fetch-and-train-new.png"
      alt="Training process for newly added data sources"
    />
  </Frame>
  **Multi-source training:**
  - **Fetch new content**: Scrape additional data sources.
  - **Integrate content**: Combine with the existing knowledge base.
  - **Retrain system**: Update embeddings with new content.
  - **Unified knowledge**: All sources work together seamlessly.
  <Frame>
    <img
      src="/images/dashboard/agent/knowledge/website/step-9-trained-new.png"
      alt="Completed training for all data sources"
    />
  </Frame>
  <Check>
    All data sources have been successfully trained and integrated into your
    knowledge base.
  </Check>
</Step>

<Step title="Knowledge base ready">
  Your website-based knowledge base is now complete and available in your knowledge bases library.
  
  <Frame>
  <img src="/images/dashboard/agent/knowledge/website/step-10-kb-added-to-my-kbs.png" alt="Completed knowledge base showing in My Knowledge Bases with status and data sources" />
  </Frame>
  
  **Knowledge base details:**
  - **Name and description**: Your configured knowledge base information
  - **Creation date**: When the knowledge base was created
  - **Training status**: Confirmed as trained and ready
  - **Data sources count**: Number of websites/content sources included
  - **Configure button**: Access to modify settings and add more sources
  
  <Note>
  **Ready to Use**: Your knowledge base is immediately available for connecting to AI Agents and providing intelligent responses based on your website content.
  </Note>
</Step>
</Steps>
